/*globals define*/

/**
 * Generated by RestRouterGenerator 2.2.0 from webgme on Sat Jul 16 2022 17:34:15 GMT-0500 (Central Daylight Time).
 * To use in webgme add to gmeConfig.rest.components[DatabaseSelector] = {
 *    mount: 'path/subPath',
 *    src: path.join(process.cwd(), './DatabaseSelector'),
 *    options: {}
 * }
 * If you put this file in the root of your directory the above will expose the routes at
 * <host>/path/subPath, for example GET <host>/path/subPath/getExample will be routed to the getExample below.
 */

'use strict';

// http://expressjs.com/en/guide/routing.html
const express = require('express');
const router = express.Router();
const bodyParser = require('body-parser');
// const formidable = require('formidable');
const multer = require('multer');
// const upload = multer({dest:'./upload'});
// const upload = require('express-fileupload');
const agent = require('superagent');
const Q = require('q');
const https = require('https');
const url = require('url');
const fs = require('fs');
const zip = require('zip-a-folder').zip;
const COMPRESSION_LEVEL = require('zip-a-folder').COMPRESSION_LEVEL;
const upload = multer({storage:multer.memoryStorage(), preservePath:true});
const busboy = require('busboy');

// const multipart = require('connect-multiparty');
// const multipartMiddleware = multipart();
const multiparty = require('multiparty');
const { seedProjects } = require('webgme/config/config.default');

let mainConfig = null;

//TODO: these parameters should be configurable - also might be asking for some layering
const pdpBase = 'https://leappremonitiondev.azurewebsites.net/v2/';
const getAccessToken = (req) => {
    return req.cookies[mainConfig.authentication.azureActiveDirectory.cookieId];
};

const getProcessObservations = (pid, token) => {
    const deferred = Q.defer();
    agent
    .get(pdpBase + 'Process/GetProcessState')
    .query({processId: pid})
    .set('Authorization', 'Bearer ' + token)
    .then(resp => {
        if(resp.ok !== true) {
            throw new Error('Cannot fetch process info ['+ pid + '] [' + resp.statusCode +']');
        }
        const obsInfo = resp.body;
        const promises = [];
        for(let i=1; i<obsInfo.numObservations; i+=1) {
            promises.push(agent
                .get(pdpBase + 'Process/GetObservation?processId=' + pid + '&obsIndex=' + i)
                .set('Authorization', 'Bearer ' + token));
        }
        return Q.all(promises);
    })
    .then(results => {
        const observations = [];
         results.forEach(result => {
            observations.push(result.body);
         });
         deferred.resolve(observations);
    })
    .catch(deferred.reject);
    
    return deferred.promise;
};

const listArtifacts = (type, token) => {
    const deferred = Q.defer();
    let processList = [];
    let itemList = []; 
    // console.log('LD ', type, token);
    agent
    .get(pdpBase+'Process/ListProcesses')
    .query({permission: 'read'})
    .set('Authorization', 'Bearer ' + token)
    .then(response => {
        // console.log(response.ok);
        // console.log(response.statusCode);
        // console.log(typeof response.body);
        // console.log(response.body);
        if(response.ok !== true) {
            throw new Error('Initial list fetching failed [' + response.statusCode +']');
        }
        
        processList = response.body.filter(element => element.processType === type);

        return Q.all(processList.map(process => {
            const d = Q.defer();
            getProcessObservations(process.processId, token)
            .then(list => {
                itemList = itemList.concat(list);
                d.resolve(true);
            })
            .catch(d.reject);
            return d.promise;
        })); 
    })
    .then(results => {
        deferred.resolve(itemList);
    })
    .catch(deferred.reject);
    return deferred.promise;
};

const _createDir = (pid, token) => {
    const deferred = Q.defer();

    const req = https.request({
        host:'leappremonitiondev.azurewebsites.net',
        path:'/v2/Files/CreateDirectory?processId=' + pid + '&isUpload=false&expiresInMins=10',
        headers: {
            Authorization: 'Bearer ' + token
        },
        method: 'PUT'
    }, res => {
        if(res.statusCode !== 200) {
            return deferred.reject(new Error('failed to create transfer directory'));
        }

        res.on('data', d => {
            const responseBody = new Buffer.from(d).toString();
            
            try {
                return deferred.resolve(JSON.parse(responseBody));
            } catch (e) {
                return deferred.reject(e);
            }
        });
    });

    req.on('error', error => {
        // console.error(error);
        return deferred.reject(error);
    });

    req.end();

    return deferred.promise;
};

const _transferObsFiles = (pid, index, did, token) => {
    const deferred = Q.defer();

    const req = https.request({
        host:'leappremonitiondev.azurewebsites.net',
        path:'/v2/Files/GetObservationFiles?processId=' + pid + 
        '&directoryId=' + did + '&obsIndex=' + index + '&endObsIndex=' + index +
        '&filePattern=%2A%2A%2F%2A.%2A',
        headers: {
            Authorization: 'Bearer ' + token
        },
        method: 'PUT'
    }, res => {
        if(res.statusCode !== 200) {
            console.log(res.statusCode);
            return deferred.reject(new Error('failed to create transfer directory'));
        }

        res.on('data', d => {
            const responseBody = new Buffer.from(d).toString();
            
            try {
                setTimeout(() => {
                    return deferred.resolve(responseBody);
                }, 60);
            } catch (e) {
                return deferred.reject(e);
            }
        });
    });

    req.on('error', error => {
        // console.error(error);
        return deferred.reject(error);
    });

    req.end();

    return deferred.promise;
};

const _listTransfers = (pid, did, token) => {
    const deferred = Q.defer();

    const req = https.request({
        host:'leappremonitiondev.azurewebsites.net',
        path:'/v2/Files/ListTransfers?processId=' + pid + 
        '&directoryId=' + did,
        headers: {
            Authorization: 'Bearer ' + token
        },
        method: 'GET'
    }, res => {
        if(res.statusCode !== 200) {
            console.log(res.statusCode);
            return deferred.reject(new Error('failed to check on transfers'));
        }

        res.on('data', d => {
            const responseBody = new Buffer.from(d).toString();
            
            try {
                setTimeout(() => {
                    return deferred.resolve(responseBody);
                }, 60);
            } catch (e) {
                return deferred.reject(e);
            }
        });
    });

    req.on('error', error => {
        // console.error(error);
        return deferred.reject(error);
    });

    req.end();

    return deferred.promise;
};

const _waitForTransfer = (pid, did, tid, time, token) => {
    const deferred = Q.defer();

    const req = https.request({
        host:'leappremonitiondev.azurewebsites.net',
        path:'/v2/Files/GetTransferState?processId=' + pid + 
        '&directoryId=' + did + '&transferId=' + tid /*+ '&lastUpdate=' + time*/,
        headers: {
            Authorization: 'Bearer ' + token
        },
        method: 'GET'
    }, res => {
        // console.log(Object.keys(res));
        console.log(res.statusMessage);
        if(res.statusCode !== 200) {
            console.log(res.statusCode);
            // return deferred.reject(new Error('failed to create transfer directory'));
            return deferred.resolve(null);
            // setTimeout(() => {
                // return _waitForTransfer(pid, did, tid, time, token);
            // }, 10000);
        }

        res.on('data', d => {
            const responseBody = new Buffer.from(d).toString();
            console.log(responseBody);
            try {
                return deferred.resolve(responseBody);
            } catch (e) {
                return deferred.reject(e);
            }
        });
    });

    req.on('error', error => {
        console.error(error);
        return deferred.reject(error);
    });

    req.end();

    return deferred.promise;
};

const _getObsFiles = (pid, index, token) => {
    const deferred = Q.defer();
    let response = '';
    const req = https.request({
        host:'leappremonitiondev.azurewebsites.net',
        path:'/v3/Files/GetObservationFiles?processId=' + pid + 
        '&obsIndex=' + index + '&expiresInMins=10&endObsIndex=' + index +
        '&filePattern=%2A%2A%2F%2A.%2A',
        headers: {
            Authorization: 'Bearer ' + token
        },
        method: 'PUT'
    }, res => {
        if(res.statusCode !== 200) {
            console.log(res.statusCode);
            return deferred.reject(new Error('failed to create transfer directory'));
        }

        res.on('data', d => {
            response += new Buffer.from(d).toString();
        });

        res.on('end', () => {
            try {
                // console.log(response);
                return deferred.resolve(JSON.parse(response));
            } catch (e) {
                return deferred.reject(e);
            }
        });
    });

    req.on('error', error => {
        // console.error(error);
        return deferred.reject(error);
    });

    req.end();

    return deferred.promise;
};

const _getFileName = (fullPath) => {
    const pathArray = fullPath.split('/');
    return pathArray[pathArray.length-1];
};

const _getFile = (path, url) => {
    console.log('GF:',path,url);
    const deferred = Q.defer();
    const pathArray = path.split('/');
    for(let i=1;i<pathArray.length-1;i+=1) {
        let inpath = '';
        for(let j=0;j<=i;j+=1) {
            inpath += pathArray[j] + '/';
        }
        inpath = inpath.slice(0, -1);
        if (!fs.existsSync(inpath)) {
            console.log('letsDIR:', inpath);
            fs.mkdirSync(inpath);
        }
    }
    const writeStream = fs.createWriteStream(path);
    https.get(url, response => {
        response.pipe(writeStream);
        writeStream.on('finish', () => {
            writeStream.close();
            deferred.resolve(path);
        });
    });

    return deferred.promise;
};

const _prepareDownloadDir = () => {
    console.log(__dirname);
    const length = 16;
    let downloadDir = '';
    let downloadName = '';
    const characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
    const charactersLength = characters.length;
    for (let i = 0; i < length; i += 1 ) {
        downloadName += characters.charAt(Math.floor(Math.random() * charactersLength));
    }
    downloadDir = './OUTPUT/' + downloadName;
    const err = fs.mkdirSync(downloadDir);
    if (err) {
        throw new Error('canot reserve local directory for transfering data');
    }

    return downloadName;
};

const _correctFilePath = (downloadDir, filename, index) => {
    const result = downloadDir + filename.replace('dat/'+index, '');
    console.log(downloadDir,filename);
    console.log(result);
    return result;
};


const downloadObservation = (pid, index, token) => {
    const deferred = Q.defer();
    let downloadDir = null;
    let downloadName = null;

    _getObsFiles(pid, index, token)
    .then(response => {
        // console.log(response);
        //download all files into files of their places...
        downloadName = _prepareDownloadDir();
        downloadDir = './OUTPUT/' + downloadName;
        const promises = [];
        response.files.forEach(file => {
            promises.push(_getFile(_correctFilePath(downloadDir,file.name, index), file.sasUrl));
        });
        return Q.all(promises);
    })
    .then(results => {
        return zip(downloadDir, './OUTPUT/' + downloadName + '.zip', {compression:COMPRESSION_LEVEL.medium});
    })
    .then(() => {
        fs.rmdirSync(downloadDir,{recursive:true});
        deferred.resolve('./OUTPUT/' + downloadName + '.zip');
    })
    .catch(deferred.reject);

    return deferred.promise;
};

const uploadProjectFromPDPToBlob = (pid, index, token) => {
    const deferred = Q.defer();
    let downloadDir = null;
    let downloadName = null;
    let downloadPath = null;
    let promise = null;

    _getObsFiles(pid, index, token)
    .then(response => {
        console.log(response);
        downloadName = _prepareDownloadDir();
        downloadDir = './OUTPUT/' + downloadName;
        response.files.forEach(file => {
            if(file.name.indexOf('webgmex') !== -1) {
                promise = file;
            } 
        });

        downloadPath = _correctFilePath(downloadDir,promise.name, index);
        console.log('file: ', downloadPath);
        return _getFile(downloadPath, promise.sasUrl);
    })
    .then((result) => {
        console.log('if any: ', result);
        const projectObject = fs.readFileSync(downloadPath);

        return agent.get('/api/blob/createFile/' + _getFileName(downloadPath));
    })
    .then(response => {
        console.log(response.body);
        fs.rmdirSync(downloadDir,{recursive:true});
        deferred.resolve(response.body);
    })
    .catch(deferred.reject);

    return deferred.promise;
};

/**
 * Called when the server is created but before it starts to listening to incoming requests.
 * N.B. gmeAuth, safeStorage and workerManager are not ready to use until the start function is called.
 * (However inside an incoming request they are all ensured to have been initialized.)
 *
 * @param {object} middlewareOpts - Passed by the webgme server.
 * @param {GmeConfig} middlewareOpts.gmeConfig - GME config parameters.
 * @param {GmeLogger} middlewareOpts.logger - logger
 * @param {function} middlewareOpts.ensureAuthenticated - Ensures the user is authenticated.
 * @param {function} middlewareOpts.getUserId - If authenticated retrieves the userId from the request.
 * @param {object} middlewareOpts.gmeAuth - Authorization module.
 * @param {object} middlewareOpts.safeStorage - Accesses the storage and emits events (PROJECT_CREATED, COMMIT..).
 * @param {object} middlewareOpts.workerManager - Spawns and keeps track of "worker" sub-processes.
 */
function initialize(middlewareOpts) {
    var logger = middlewareOpts.logger.fork('DatabaseSelector'),
        ensureAuthenticated = middlewareOpts.ensureAuthenticated,
        getUserId = middlewareOpts.getUserId;

    mainConfig = middlewareOpts.gmeConfig;

    logger.debug('initializing ...');

    // Ensure authenticated can be used only after this rule.
    router.use((req, res, next) => {
        // TODO: set all headers, check rate limit, etc.

        // This header ensures that any failures with authentication won't redirect.
        res.setHeader('X-WebGME-Media-Type', 'webgme.v1');
        next();
    });

    // Use ensureAuthenticated if the routes require authentication. (Can be set explicitly for each route.)
    router.use(ensureAuthenticated);

    const myLogger = (req, res, next) => {
        console.log('LOGGED:', req.body);
        next();
    };

    // router.use(myLogger);
    // router.use(upload());
    // router.use(express.urlencoded({ extended: true }));
    // for parsing application/json
    router.use(bodyParser.json()); 
    // router.use(upload.any());

    // for parsing application/xwww-
    // router.use(bodyParser.urlencoded({ extended: true })); 
//form-urlencoded
    // router.use(upload.array());

    // router.get('/data/:projectId?/:branch?/:path?', function (req, res/*, next*/) {
        // var userId = getUserId(req);
// 
        // res.json({userId: userId, message: 'get request was handled', path:req.query.path, pid: req.query.projectId, branch: req.query.branch});
    // });

    router.get('/project/:projectId?/:branch?', function (req, res/*, next*/) {
        var userId = getUserId(req);

        res.json({userId: userId, message: 'get request was handled', pid: req.query.projectId, branch: req.query.branch});
    });

    // Known types are: data, workflow, experiment
    router.get('/list/:type', (req, res) => {
        // console.log('LISTDATA');
        listArtifacts(req.params.type, getAccessToken(req))
        .then(full_list => {
            // console.log('LISTDATA-ARRIVED:', full_list);
            res.status(200).json(full_list).end();
        })
        .catch(err => {
            // console.log('LISTDATA-FAILED:', err);
            res.sendStatus(401);
        });
    });

    router.get('/data/:pid/:index', (req, res) => {
        downloadObservation(req.params.pid, req.params.index, getAccessToken(req))
        .then(path => {
            // console.log(archivePath);
            // console.log(getAccessToken(req));
            // res.header('Authorization', 'Bearer ' + getAccessToken(req));
            // res.redirect(sasURL);
            res.download(path,(err) => {
                console.log('finished sending download - so just remove everything');
                // setTimeout(()=> {
                    fs.rmSync(path,{force: true});
                // }, 60000); //TODO how to properly know when the download finished???
            });
        })
        .catch(err => {
            console.log(err);
            res.sendStatus(401);
        });
    });

    router.get('/boot/:pid/:index/:name', (req, res) => {
        console.log('we arrived');
        uploadProjectFromPDPToBlob(req.params.pid, req.params.index, getAccessToken(req))
        .then(hash => {
            return seedProject(hash, req.params.name, getAccessToken(req));
        })
        .then((result) => {
            res.status(200).json({success:true, name: result.actualName, projectId: result.projectId});
        })
        .catch(e => {
            console.error(e);
            return res.sendStatus(500);
        });
    });
    /*const upfile = upload.single('file');
    router.post('/data/:pid', (req, res) => {
        console.log('fuckyeah:');
        upfile(req,res, (err) => {
            if (err) {
                console.log(err);
                return res.sendStatus(500);
            }
            console.log(req.body);
            console.log(JSON.parse(req.body.meta));
            console.log(req.file);
            res.sendStatus(200); 
        }); 
    });*/

    router.post('/data/:pid', (req, res) => {
        console.log('here');

        const bb = busboy({ headers: req.headers });
        bb.on('file', (name, file, info) => {
            console.log(name, info);
            const saveTo = path.join(os.tmpdir(), `busboy-upload-${random()}`);
            file.pipe(fs.createWriteStream(saveTo));
          });
          bb.on('close', () => {
            res.writeHead(200, { 'Connection': 'close' });
            res.end(`That's all folks!`);
          });
          req.pipe(bb);
      });
      


    // router.patch('/patchExample', function (req, res/*, next*/) {
    //     res.sendStatus(200);
    // });


    // router.post('/postExample', function (req, res/*, next*/) {
    //     res.sendStatus(201);
    // });

    // router.delete('/deleteExample', function (req, res/*, next*/) {
    //     res.sendStatus(204);
    // });

    // router.get('/error', function (req, res, next) {
    //     next(new Error('error example'));
    // });

    logger.debug('ready');
}

/**
 * Called before the server starts listening.
 * @param {function} callback
 */
function start(callback) {
    callback();
}

/**
 * Called after the server stopped listening.
 * @param {function} callback
 */
function stop(callback) {
    callback();
}


module.exports = {
    initialize: initialize,
    router: router,
    start: start,
    stop: stop
};
